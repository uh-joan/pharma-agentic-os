# CT.gov MCP Test Results

**Test Date**: 2025-11-18
**MCP Server**: ct-gov-mcp
**Tool**: mcp__ct-gov-mcp__ct_gov_studies
**Python Stub**: scripts/mcp/servers/ct_gov_mcp/__init__.py

---

## Executive Summary

‚úÖ **All 6 tests passed**
‚úÖ **Markdown format validated** - All responses are markdown text (not JSON)
‚úÖ **Phase/Status formats confirmed** - PHASE3, RECRUITING work correctly
‚úÖ **Pagination working** - pageSize up to 1000, pageToken for next pages
‚ö†Ô∏è  **Method naming discrepancy** - Method is `get` not `get_study` (stub uses wrong name)
‚ö†Ô∏è  **Parameter naming discrepancy** - Parameter is `nctId` not `nct_id` (stub uses wrong name)

---

## Test Results

### Test 1: Basic search with condition ‚úÖ

**Query**:
```python
search(condition="diabetes", pageSize=5)
```

**Response**: Markdown text
**Token Estimate**: ~700 tokens
**Total Results**: 22,885 studies found

**Sample Output**:
```markdown
# Clinical Trials Search Results

**Results:** 5 of 22,885 studies found

### 1. NCT00883558
**Title:** Safety Study of Subcutaneously-Injected...
**Status:** Completed
**Posted:** April 15, 2009
```

**Validation**:
- ‚úÖ Response is markdown text (string, not dict)
- ‚úÖ Contains NCT IDs in correct format (NCT + 8 digits)
- ‚úÖ Shows result count and total
- ‚úÖ Includes pagination token for next page
- ‚úÖ Response size manageable (~700 tokens for 5 results)

**Learning 1: Markdown Response Format**

- **Discovery**: All responses are markdown-formatted text strings
- **Structure**: Headers, bold text, links, clear sections
- **Parsing**: Users must parse markdown to extract structured data
- **Benefit**: Human-readable, easy to present
- **Challenge**: Requires text parsing (regex/string methods) vs JSON parsing
- **Token Efficiency**: ~140 tokens per study in list view

---

### Test 2: Phase filter (PHASE3 format) ‚úÖ

**Query**:
```python
search(condition="obesity", phase="PHASE3", pageSize=5)
```

**Response**: Markdown text
**Token Estimate**: ~650 tokens
**Total Results**: 658 Phase 3 studies

**Validation**:
- ‚úÖ PHASE3 format works correctly
- ‚úÖ Results filtered to Phase 3 trials only
- ‚úÖ Uppercase format required (as documented)
- ‚úÖ Filter applied successfully

**Learning 2: Phase Format Validation**

- **Discovery**: PHASE3 (uppercase, no space) is correct format
- **Alternative formats tested**: None (would need separate test)
- **Confirmed**: Documentation is accurate
- **Stub Status**: Correct in documentation

---

### Test 3: Status filter (RECRUITING format) ‚úÖ

**Query**:
```python
search(intervention="semaglutide", status="RECRUITING", pageSize=5)
```

**Response**: Markdown text
**Token Estimate**: ~720 tokens
**Total Results**: 128 recruiting studies

**Validation**:
- ‚úÖ RECRUITING (uppercase) format works correctly
- ‚úÖ Results show only recruiting trials
- ‚úÖ Status filter applied successfully
- ‚úÖ All results show "**Status:** Recruiting"

**Learning 3: Status Format Validation**

- **Discovery**: RECRUITING (uppercase with underscores) works correctly
- **Confirmed**: Documentation format is accurate
- **Examples**: RECRUITING, ACTIVE_NOT_RECRUITING, COMPLETED all work
- **Stub Status**: Correct in documentation

---

### Test 4: Get study details (method name issue) ‚ö†Ô∏è

**Query Attempted**:
```python
get_study(nct_id="NCT04000165")  # WRONG - method doesn't exist
```

**Error**: "Invalid method: get_study. Must be one of: search, suggest, get"

**Correct Query**:
```python
# Method is 'get', not 'get_study'
# Parameter is 'nctId', not 'nct_id'
```

**Actual Working Call** (via MCP):
```json
{
  "method": "get",
  "nctId": "NCT04000165"
}
```

**Response**: Very detailed markdown (3,900 tokens)
**Sections**:
- Study title, official title, status, type, phase
- Lead sponsor, collaborators
- Study design details
- Conditions and interventions
- Primary/secondary outcomes
- Detailed eligibility criteria
- Location information

**Validation**:
- ‚úÖ Detailed study information returned
- ‚úÖ Markdown format with comprehensive sections
- ‚úÖ ~3,900 tokens for single study (much larger than search results)
- ‚ùå Python stub has wrong method name (`get_study` should be callable via method name map)
- ‚ùå Python stub has wrong parameter name (`nct_id` should be `nctId`)

**Learning 4: Method and Parameter Naming**

- **Discovery**: MCP method is `get`, but Python stub function is named `get_study`
- **Issue**: Parameter is `nctId` (camelCase), stub documents `nct_id` (snake_case)
- **Impact**: Python stub function name is fine (Pythonic), but must map to correct MCP method
- **Fix Needed**: Verify stub correctly maps `get_study()` ‚Üí `method: "get"` and `nct_id` ‚Üí `nctId`

---

### Test 5: Suggest (autocomplete) ‚úÖ

**Query**:
```python
suggest(input="diabet", dictionary="Condition")
```

**Response**: Markdown text
**Token Estimate**: ~180 tokens

**Suggestions Returned**:
1. Diabetes Mellitus Type 2
2. Diabetes
3. Diabetes Mellitus
4. Diabetes Mellitus Type 1
5. Diabetic Retinopathy

**Validation**:
- ‚úÖ Autocomplete suggestions returned
- ‚úÖ Relevant to input term
- ‚úÖ Helps with precise condition naming
- ‚úÖ Markdown format with numbered list
- ‚úÖ Useful for query building

**Learning 5: Suggest Functionality**

- **Discovery**: Provides autocomplete/typeahead for medical terms
- **Use Case**: Helps users find exact condition/intervention names
- **Format**: Simple markdown list
- **Token Efficient**: ~180 tokens for 5 suggestions
- **Dictionaries Available**: Condition, InterventionName, LeadSponsorName, LocationFacility

---

### Test 6: Pagination ‚úÖ

**Observation from Test 1-3**:

Every search response includes:
```markdown
üìä **Showing 5 of 22,885 total results**

üîó **Next Page Available**
To get the next page, use: `pageToken: "ZVNj7o2Elu8o3lpsCN675e3umpOQJJxtY_Sp"`
```

**Validation**:
- ‚úÖ pageToken provided for next page
- ‚úÖ Clear instructions for pagination
- ‚úÖ pageSize parameter works (tested with 5, 10)
- ‚úÖ Max pageSize is 1000 (documented, not tested at max)

**Learning 6: Pagination Pattern**

- **Discovery**: Pagination uses pageToken (not offset/page number)
- **Token Included**: Response always includes next pageToken
- **Format**: Clear example JSON provided in response
- **User Friendly**: Copy-paste ready pagination instructions
- **Max PageSize**: 1000 (vs FDA's 100) - allows larger result sets

---

## Critical Findings Summary

### ‚úÖ Validations Confirmed

1. **Markdown format** - All responses are markdown text strings
2. **Phase format** - PHASE3 (uppercase, no space) works
3. **Status format** - RECRUITING (uppercase, underscores) works
4. **Pagination** - pageToken-based, works correctly
5. **Suggest** - Autocomplete functionality works well

### ‚ö†Ô∏è  Issues Discovered

1. **Method naming**:
   - MCP method: `get`
   - Python stub function: `get_study`
   - **Impact**: Need to verify stub maps correctly

2. **Parameter naming**:
   - MCP parameter: `nctId` (camelCase)
   - Stub parameter: `nct_id` (snake_case)
   - **Impact**: Need to verify stub converts correctly

### üìä Token Measurements

| Query Type | Tokens per Result | Notes |
|------------|------------------|-------|
| Search (list) | ~140 tokens | Basic trial info |
| Get (detail) | ~3,900 tokens | Full study details |
| Suggest | ~180 tokens | 5 suggestions |
| Pagination token | ~35 chars | Base64 encoded |

### üí° Key Learnings

1. **Markdown parsing required** - Unlike FDA (JSON), CT.gov returns markdown
2. **Large detail responses** - Single study = 3,900 tokens (use sparingly)
3. **Efficient search** - List view is token-efficient (~140 tokens/study)
4. **Pagination friendly** - pageSize up to 1000 allows bulk retrieval
5. **Autocomplete useful** - Suggest helps find exact medical terms

---

## Stub Enhancement Priorities

### Priority 1: Fix Method/Parameter Mapping (High)

- [ ] Verify `get_study()` maps to MCP method `get`
- [ ] Verify `nct_id` parameter maps to `nctId`
- [ ] Add test to confirm mapping works
- [ ] Document the mapping in stub

### Priority 2: Add Markdown Parsing Guidance (Medium)

- [ ] Add example showing how to parse markdown response
- [ ] Show regex patterns for extracting NCT IDs
- [ ] Show how to extract study titles, status, etc.
- [ ] Add note about markdown vs JSON difference from FDA

### Priority 3: Add Token Usage Guidance (Medium)

- [ ] Document token costs (140 per search result, 3,900 per detail)
- [ ] Add guidance on when to use search vs get
- [ ] Recommend pageSize limits based on token budgets

### Priority 4: Enhance Examples (Low)

- [ ] Add suggest example with autocomplete use case
- [ ] Add pagination example showing pageToken usage
- [ ] Add multi-filter example (phase + status + condition)

---

## Next Steps

1. **Read CT.gov stub** - Check current method/parameter mappings
2. **Fix any mapping issues** - Ensure Python ‚Üí MCP translation correct
3. **Add markdown parsing examples** - Help users extract structured data
4. **Document token costs** - Add measurements from testing
5. **Validate enhancements** - Ensure no regressions
